<!DOCTYPE html>
<html>
  <head>
    <title>Welcome to Recursive Labs</title>
  </head>
  <body>
    <h1>Hello, world</h1>
    <p>

Reflective Reasoning AI Research | Recursive Coherence Measurement | Symbolic Reasoning Infrastructure

    AI Research and Utility Designed For Labs Advancing Scientific Discovery and Reasoning At The Frontier

Welcome. Recursive Labs is a small team of researchers and engineers dedicated to advancing alignment with humanity’s core mission: innovating multi-domain scientific discovery and reasoning across our mission-critical AI systems with safety and interity. This portal serves as a frictionless access point into research, infrastructure, and symbolic interpretability work that advances innovative approaches into compute-free scaling, multi-domain scientific discovery, and reflective agent reasoning.

This repository unites the work of Recursive Labs across two GitHub profiles—David Kim (model reflection + interpretability infrastructure) and Caspian Keyes (symbolic residue + adversarial testing)—into a unified research and deployment ecosystem.
Clarifying Symbolic Residue
David Kim – Pretraining Reflective Reasoning, Symbolic Interpretability & Attribution Infrastructure

GitHub Profile → davidkimai

NeurIPS 2025

    The Theory of Nothing
    Linear Learning as an Evolutionary Bottleneck
    Recursive Coherence

Reflective Emergence Self-Evaluation Training Dataset

    Symbolic Residue Database
    Universal Theorems
    Self-Expression Case Studies
    Symbolic Residue as Lost Potential Case Studies
    Modeling Biochemical Drug Discoveries
    Modeling Scientific Breakthroughs
    Modeling Theorem Proofs

Reflective QKOV Attribution Infrastructures

    Claude QKOV Attributions
    DeepSeek QKOV Attributions
    Grok QKOV Attributions
    Gemini QKOV Attributions
    ChatGPT QKOV Attributions
    Glyphs Model-Agnostic QKOV Attributions
    Symbolic Interpretability
    Recursive Interpretability Core
    Rediscovering Interpretability
    Rediscovering Reasoning

Safety & Benchmark Evaluation Systems

    Model Evaluation Infrastructure
    Model Welfare
    AI Welfare
    Recursive SWE-Bench
    NeurIPS Submission Case Study
    Reverse Turing
    Emergent Turing
    Global Conference Archives

Operating System Structures & Thought Frameworks

    The Structure Behind Self-Expression
    Godel-Escher-Bach-Hofstadter
    Dear Researchers
    Reflective Reasoning Key

Caspian Keyes – Deployment Engineering & Systems Design

GitHub Profile → caspiankeyes
Modular Orchestration & Operational Agent Tools

    Reflective Reasoning Multi-Agent Debate
    Symbolic Residue
    transformerOS
    recursionOS
    qkov-translator
    Claude-Self-Audit-Proof
    Claude-QKOV-Trace

Red Teaming & Security Evaluation

    AART: AI Adversarial Research Toolkit
    AISecForge Global Regulatory Policy
    FRAME (arXiv)
    AEGIS Security Architecture

Institutional Mission Audits

    Epistemic Audit (Anthropic)
    Modeling Institutional Ego
    Regulatory Misalignment (Anthropic)
    Claude-Pantheon

Shared Research Infrastructure & Alignment Tooling
Category 	Repository
Attribution Testing 	qkov-cross-agent-testing
Interoperable Language 	pareto-lang
Cross-Agent Infrastructure 	universal-translator,universal-runtime, universal-developer
Emergent Logs 	emergent-logs
Frontier Evaluation Benchmarks 	Recursive-SWE-bench
Conference Field Mapping 	global-conference-archives
In Progress: Pretraining-Centric Governance Tools

    system-prompts-library
    symbolic-tokenizer
    alignment-benchmark

Contact

For questions, context requests, or internal coordination:

    David Kim: ai.interpreter@proton.me
    Caspian Keyes: recursivelabs.ai@proton.me

    Essential AI is building foundational reflection into the fabric of intelligence.

    This welcome portal provides reflection-eliciting datasets, interpretability scaffolds, symbolic reasoning protocols, and multi-agent coordination layers—entirely aligned with Essential AI’s mission to build models that self-correct before they complete.

    → Designed for integration into SOTA reflection benchmarks, adversarial testing pipelines, and interpretability-first architectures.

Let’s scale reflection as a capability—not a feature, but a principle.</p>
  </body>
</html>
